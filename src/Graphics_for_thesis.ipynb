{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6332ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d65d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Orange\n",
    "from orangecontrib.bioinformatics import geo\n",
    "import serverfiles\n",
    "\n",
    "from L1000 import L1000\n",
    "from geo_dataset import Dataset\n",
    "from geo_models import AutoEncoder, MultiTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f38e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZES = [4, 5, 6, 7, 8, 10, 12, 16, 32, 64]\n",
    "COLORS = list(mcolors.TABLEAU_COLORS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa584a95",
   "metadata": {},
   "source": [
    "- [Methods](#Methods)\n",
    "- [GEO database](#GEO-database)\n",
    "- [Data selection](#Data-selection)\n",
    "- [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46676dcc",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bbcd8",
   "metadata": {},
   "source": [
    "### activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    ex = np.exp(x)\n",
    "    e_x = np.exp(-x)\n",
    "    return (ex-e_x)/(ex+e_x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def leakyrelu(x, alpha=0.1):\n",
    "    return np.maximum(alpha*x, x)\n",
    "\n",
    "def gelu(x):\n",
    "    sqrt2 = math.sqrt(2)\n",
    "    y = np.array([math.erf(x_/sqrt2) for x_ in x])\n",
    "    return 0.5*x*(1+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b785e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "plt.plot(x, sigmoid(x), label=\"sigmoid\")\n",
    "plt.plot(x, tanh(x), label=\"tanh\")\n",
    "plt.plot(x, relu(x), label=\"ReLU\")\n",
    "plt.plot(x, leakyrelu(x), label=\"leaky ReLU\")\n",
    "plt.plot(x, gelu(x), label=\"GELU\")\n",
    "plt.ylim(-1.1, 2)\n",
    "plt.legend(loc=\"upper left\", fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eddcc0",
   "metadata": {},
   "source": [
    "### derivatives of activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da364d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-tanh(x)**2\n",
    "\n",
    "def relu_prime(x):\n",
    "    return (x > 0)*1\n",
    "\n",
    "def leakyrelu_prime(x, alpha=0.1):\n",
    "    tmp = relu_prime(x).astype(float)\n",
    "    tmp[tmp == 0] = alpha\n",
    "    return tmp\n",
    "\n",
    "def gelu_prime(x):\n",
    "    sqrt2 = math.sqrt(2)\n",
    "    y = np.array([math.erf(x_/sqrt2) for x_ in x])\n",
    "    return 0.5*(1+y) + x*stats.norm.pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5570a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "plt.plot(x, sigmoid_prime(x), label=\"sigmoid\")\n",
    "plt.plot(x, tanh_prime(x), label=\"tanh\")\n",
    "plt.plot(x, relu_prime(x), label=\"ReLU\")\n",
    "plt.plot(x, leakyrelu_prime(x), label=\"leaky ReLU\")\n",
    "plt.plot(x, gelu_prime(x), label=\"GELU\")\n",
    "#plt.ylim(-1.1, 2)\n",
    "plt.legend(loc=\"upper left\", fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826d44e",
   "metadata": {},
   "source": [
    "# GEO database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1000 = L1000(\"../data/L1000/L1000.tab\")\n",
    "ORANGE_GEO_URL = \"https://download.biolab.si/datasets/geo/\"\n",
    "server_files = serverfiles.ServerFiles(server=ORANGE_GEO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = server_files.allinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497bbe6",
   "metadata": {},
   "source": [
    "### sample_organism distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098824c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_organism = np.array([v[\"sample_organism\"] for v in data_info.values()])\n",
    "(organisms, counts) = np.unique(sample_organism, return_counts=True)\n",
    "idx = np.argsort(-counts)\n",
    "organisms = organisms[idx]\n",
    "counts = counts[idx]\n",
    "\n",
    "print(len(organisms))\n",
    "for o, c in zip(organisms, counts):\n",
    "    print(o, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95091e83",
   "metadata": {},
   "source": [
    "### sample_count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec17374",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = np.array([int(v[\"sample_count\"]) for v in data_info.values()])\n",
    "print(\"minimum:\", np.min(sample_count))\n",
    "print(\"maximum:\", np.max(sample_count))\n",
    "print(\"average:\", np.mean(sample_count))\n",
    "print(\"standard deviation:\", np.std(sample_count))\n",
    "print(\"mode:\", stats.mode(sample_count, keepdims=False).mode)\n",
    "\n",
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.hist(sample_count, bins=range(0, 220, 5), rwidth=0.85, color=\"deepskyblue\", edgecolor=\"black\", linewidth=1, log=True)\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Number of datasets\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b7341",
   "metadata": {},
   "source": [
    "### sample_type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73518631",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type = np.array([v[\"sample_type\"] for v in data_info.values()])\n",
    "(types, counts) = np.unique(sample_type, return_counts=True)\n",
    "for t, c in zip(types, counts):\n",
    "    print(t, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec7d4b",
   "metadata": {},
   "source": [
    "### genes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = np.array([int(v[\"genes\"]) for v in data_info.values()])\n",
    "print(\"minimum:\", np.min(genes), f\"()\")\n",
    "print(\"maximum:\", np.max(genes))\n",
    "print(\"average:\", np.mean(genes))\n",
    "print(\"standard deviation:\", np.std(genes))\n",
    "print(\"mode:\", stats.mode(genes, keepdims=False).mode)\n",
    "\n",
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.hist(genes, bins=range(0, 55000, 1000), rwidth=0.85, color=\"deepskyblue\", edgecolor=\"black\", linewidth=1, log=True)\n",
    "plt.xlabel(\"Number of gene attributes\")\n",
    "plt.ylabel(\"Number of datasets\")\n",
    "plt.xticks([10000*i for i in range(6)], [\"0\"]+[f\"{10*i}k\" for i in range(1, 6)])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69475b",
   "metadata": {},
   "source": [
    "### distribution of classes/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = list()\n",
    "class_average = list()\n",
    "for val in data_info.values():\n",
    "    subsets = defaultdict(dict)\n",
    "    for s in val[\"subsets\"]:\n",
    "        subsets[s[\"type\"]][s[\"description\"]] = len(s[\"sample_id\"])\n",
    "    for s in subsets.values():\n",
    "        class_dist.append(len(s))\n",
    "    class_average.append(len(subsets))\n",
    "class_dist = np.array(class_dist)\n",
    "class_average = np.array(class_average)\n",
    "\n",
    "print(\"Task level\")\n",
    "print(\"minimum:\", np.min(class_dist))\n",
    "print(\"maximum:\", np.max(class_dist))\n",
    "print(\"average:\", np.mean(class_dist))\n",
    "print(\"standard deviation:\", np.std(class_dist))\n",
    "print(\"mode:\", stats.mode(class_dist, keepdims=False).mode)\n",
    "print(\"\\nDataset level\")\n",
    "print(\"average:\", np.mean(class_average))\n",
    "print(\"standard deviation:\", np.std(class_average))\n",
    "print(\"mode:\", stats.mode(class_average, keepdims=False).mode)\n",
    "\n",
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.hist(class_dist, bins=range(0, 90, 2), rwidth=0.85, color=\"deepskyblue\", edgecolor=\"black\", linewidth=1, log=True)\n",
    "plt.xlabel(\"Number of classes\")\n",
    "plt.ylabel(\"Number of\\ntarget variables\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be248e3",
   "metadata": {},
   "source": [
    "### value_type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_type = np.array([v[\"value_type\"] for v in data_info.values()])\n",
    "(types, counts) = np.unique(value_type, return_counts=True)\n",
    "idx = np.argsort(-counts)\n",
    "types = types[idx]\n",
    "counts = counts[idx]\n",
    "\n",
    "for t, c in zip(types, counts):\n",
    "    print(t, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d2f9d",
   "metadata": {},
   "source": [
    "# Intro data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/samples_arrayexpress.pickle\", \"rb\") as f:\n",
    "    s_arrayexpress = pickle.load(f)\n",
    "arrayexpress = list()\n",
    "for k, v in s_arrayexpress.items():\n",
    "    if k == 201:\n",
    "        continue\n",
    "    arrayexpress.extend([k]*v)\n",
    "print(\"ArrayExpress max:\", max(arrayexpress))\n",
    "print(\"ArrayExpress <10:\", sum(1 for a in arrayexpress if a <= 10), len(arrayexpress))\n",
    "\n",
    "with open(\"../data/samples_geo.pickle\", \"rb\") as f:\n",
    "    s_geo = pickle.load(f)\n",
    "geo = list()\n",
    "for k, v in s_geo.items():\n",
    "    geo.extend([k]*v)\n",
    "print(\"GEO max:\", max(geo))\n",
    "print(\"GEO <10:\", sum(1 for a in geo if a <= 10), len(geo))\n",
    "\n",
    "with open(\"../data/samples_dbgap.pickle\", \"rb\") as f:\n",
    "    s_dbgap = pickle.load(f)\n",
    "dbgap = list()\n",
    "for k, v in s_dbgap.items():\n",
    "    dbgap.extend([k]*v)\n",
    "print(\"dbGaP max:\", max(dbgap))\n",
    "print(\"dbGaP <10:\", sum(1 for a in dbgap if a <= 10), len(dbgap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [i for i in range(0, 201, 10)]\n",
    "plt.hist(arrayexpress, bins, color=\"tab:blue\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"arrayexpress\")\n",
    "plt.hist(geo, bins, color=\"tab:orange\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"geo\")\n",
    "plt.hist(dbgap, bins, color=\"tab:green\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"dbgap\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Number of data sets\")\n",
    "plt.xticks(bins[::2], bins[::2])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e31c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../data/samples_arrayexpress.pickle\", \"rb\") as f:\n",
    "    s_arrayexpress = pickle.load(f)\n",
    "arrayexpress = list()\n",
    "for k, v in s_arrayexpress.items():\n",
    "    if k == 201:\n",
    "        continue\n",
    "    arrayexpress.extend([k]*v)\n",
    "print(\"ArrayExpress max:\", max(arrayexpress))\n",
    "print(\"ArrayExpress <10:\", sum(1 for a in arrayexpress if a <= 10), len(arrayexpress))\n",
    "\n",
    "with open(\"../data/samples_geo.pickle\", \"rb\") as f:\n",
    "    s_geo = pickle.load(f)\n",
    "geo = list()\n",
    "for k, v in s_geo.items():\n",
    "    geo.extend([k]*v)\n",
    "print(\"GEO max:\", max(geo))\n",
    "print(\"GEO <10:\", sum(1 for a in geo if a <= 10), len(geo))\n",
    "\n",
    "with open(\"../data/samples_dbgap.pickle\", \"rb\") as f:\n",
    "    s_dbgap = pickle.load(f)\n",
    "dbgap = list()\n",
    "for k, v in s_dbgap.items():\n",
    "    dbgap.extend([k]*v)\n",
    "print(\"dbGaP max:\", max(dbgap))\n",
    "print(\"dbGaP <10:\", sum(1 for a in dbgap if a <= 10), len(dbgap))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 2), dpi=200)\n",
    "\n",
    "X_TICKS = list(range(0, 101, 25)) + list(range(100, 201, 50))\n",
    "\n",
    "bins = [i for i in range(0, 201, 10)]\n",
    "ax1.hist(arrayexpress, bins, color=\"tab:blue\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"arrayexpress\")\n",
    "ax2.hist(geo, bins, color=\"tab:orange\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"geo\")\n",
    "ax3.hist(dbgap, bins, color=\"tab:green\", rwidth=0.85, edgecolor=\"black\", linewidth=1, alpha=0.5, label=\"dbgap\")\n",
    "\n",
    "#plt.yscale(\"log\")\n",
    "for i, (ax, name) in enumerate(zip([ax1, ax2, ax3], [\"ArrayExpress\", \"GEO\", \"dbGaP\"])):\n",
    "    ax.set_xlabel(\"Number of samples\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Number of data sets\")\n",
    "    #ax.set_yscale(\"log\")\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(X_TICKS, X_TICKS)\n",
    "\n",
    "ax1.set_yticklabels([\"0\", \"10k\", \"20k\", \"30k\"])\n",
    "ax2.set_yticklabels([\"0\", \"500\", \"1k\", \"1,5k\"])\n",
    "\n",
    "plt.savefig(\"../figures/data/database_distribution.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex uses 390.0pt as columnwidth -> ~13.7046cm or 5.3976in\n",
    "# https://tex.stackexchange.com/questions/8260/what-are-the-various-units-ex-em-in-pt-bp-dd-pc-expressed-in-mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0d220",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "Is in another file: GEO PCA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9f1d2",
   "metadata": {},
   "source": [
    "# Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1000 = L1000(\"../data/L1000/L1000.tab\")\n",
    "data = pd.read_csv(\"../data/GEO_v2/candidates_manual_fix_v2.csv\")\n",
    "data[\"sample_count\"] = data[\"sample_count\"].astype(int)\n",
    "data[\"class_distribution\"] = data[\"class_distribution\"].apply(eval)\n",
    "data[\"class_mapping\"] = data[\"class_mapping\"].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155bbba",
   "metadata": {},
   "source": [
    "### before cutoff stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04077f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data.groupby(\"name\")\n",
    "samples = groups[\"sample_count\"].mean().to_numpy()\n",
    "n_tasks = groups.size().to_numpy()\n",
    "print(\"Number of samples:\", int(samples.sum()))\n",
    "print(\"Number of data sets:\", len(groups))\n",
    "print(\"Number of tasks:\", n_tasks.sum())\n",
    "print(\"Average tasks per dataset:\", n_tasks.sum() / len(groups))\n",
    "num_L1000_genes = groups[\"num_L1000_genes\"].mean().to_numpy()\n",
    "print(\"Number of L1000 non-empty genes\")\n",
    "print(\"Mode:\", stats.mode(num_L1000_genes, keepdims=False).mode)\n",
    "print(\"Average:\", np.mean(num_L1000_genes))\n",
    "print(\"Standard deviation:\", np.std(num_L1000_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be28b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_samples = np.sort(samples)[::-1].cumsum() / samples.sum()\n",
    "colors = [\"tab:\"+c for c in [\"blue\", \"orange\", \"green\", \"red\", \"purple\"]]\n",
    "plt.plot(cum_samples, \"k\")\n",
    "ymin, ymax = plt.ylim()\n",
    "xmin, xmax = plt.xlim()\n",
    "for fr, c in zip([0.5, 0.6, 0.7, 0.8, 0.9], colors):\n",
    "    x_max = np.where(cum_samples > fr)[0][0]\n",
    "    plt.hlines(fr, -50, x_max, c)\n",
    "    plt.vlines(x_max, -1, fr, c)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.title(\"How many datasets cover the % of all samples\")\n",
    "plt.xlabel(\"Number of datasets\")\n",
    "plt.ylabel(\"% of all samples\")\n",
    "plt.yticks([i/10 for i in range(0, 11, 2)], [10*i for i in range(0, 11, 2)])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf28154",
   "metadata": {},
   "source": [
    "### cutoff curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_L1000_columns = dict()\n",
    "\n",
    "groups = data.groupby(\"name\")\n",
    "\n",
    "wrong_count = 0\n",
    "for name in tqdm(data[\"name\"].unique()):\n",
    "    row = data[data[\"name\"] == name].reset_index(drop=True).loc[0]\n",
    "    tmp = pd.read_csv(\"../\"+row[\"file_location\"], usecols=l1000.get_landmark_list())\n",
    "    #print(len(tmp.columns))\n",
    "    nonempty_cols = tmp.notna().all()\n",
    "    if row[\"num_L1000_genes\"] != nonempty_cols.sum():\n",
    "        print(f\"Problem with dataset {name}: {row['num_L1000_genes']} != {nonempty_cols.sum()}\")\n",
    "        wrong_count += 1\n",
    "    geo_L1000_columns[name] = set(nonempty_cols[nonempty_cols].index)\n",
    "\n",
    "def calculate_intersection(limit, geo_L1000_columns):\n",
    "    common_cols = None\n",
    "    for v in geo_L1000_columns.values():\n",
    "        if len(v) >= limit:\n",
    "            if common_cols is None:\n",
    "                common_cols = v\n",
    "            else:\n",
    "                common_cols = common_cols.intersection(v)\n",
    "    return common_cols if common_cols is not None else set()\n",
    "\n",
    "\n",
    "x, y, samples = list(), list(), list()\n",
    "for limit in tqdm(range(800, 1000, 5)):\n",
    "    common_cols = calculate_intersection(limit, geo_L1000_columns)\n",
    "    x.append(limit)\n",
    "    y.append(len(common_cols))\n",
    "    samples.append(data[data[\"num_L1000_genes\"] >= limit].groupby(\"name\")[\"sample_count\"].mean().sum())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,2), dpi=200)\n",
    "ax.plot(x, y, color=\"red\", marker=\".\")\n",
    "ax.set_ylabel(\"Common non-empty\\nL1000 gene expressions\")\n",
    "ax.set_xlabel(\"Cutoff number\")\n",
    "ax.set_yticks([0, 250, 500, 750, 1000], [0, 250, 500, 750, 1000], color=\"red\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x, samples, color=\"blue\", marker=\".\")\n",
    "ax2.set_ylabel(\"Number of samples in\\nremaining datasets\")\n",
    "ax2.set_yticks([0, 5000, 10000, 15000], [\"0\", \"5k\", \"10k\", \"15k\"], color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, samples = list(), list(), list()\n",
    "for limit in tqdm(range(950, 966, 1)):\n",
    "    common_cols = calculate_intersection(limit, geo_L1000_columns)\n",
    "    x.append(limit)\n",
    "    y.append(len(common_cols))\n",
    "    samples.append(data[data[\"num_L1000_genes\"] >= limit].groupby(\"name\")[\"sample_count\"].mean().sum())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,2), dpi=200)\n",
    "ax.plot(x, y, color=\"red\", marker=\"o\")\n",
    "ax.set_ylabel(\"Common non-empty\\nL1000 gene expressions\")\n",
    "ax.set_xlabel(\"Cutoff number\")\n",
    "ax.set_xticks(range(950, 966, 2), range(950, 966, 2))\n",
    "ax.set_yticks([825, 850, 875, 900, 925], [825, 850, 875, 900, 925], color=\"red\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x, samples, color=\"blue\", marker=\"o\")\n",
    "ax2.set_ylabel(\"Number of samples in\\nremaining datasets\")\n",
    "ax2.set_yticks([0, 5000, 10000, 15000], [\"0\", \"5k\", \"10k\", \"15k\"], color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adec6e6",
   "metadata": {},
   "source": [
    "### after cutoff sample distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = list(calculate_intersection(958, geo_L1000_columns))\n",
    "columns_to_keep.sort()\n",
    "print(f\"We will keep datasets with {len(columns_to_keep)} most common L1000 columns\")\n",
    "to_train = data[data[\"num_L1000_genes\"] >= 958]\n",
    "\n",
    "groups = to_train.groupby(\"name\")\n",
    "samples = groups[\"sample_count\"].mean().to_numpy()\n",
    "n_tasks = groups.size().to_numpy()\n",
    "print(\"Number of samples:\", int(samples.sum()))\n",
    "print(\"Number of data sets:\", len(groups))\n",
    "print(\"Number of tasks:\", n_tasks.sum())\n",
    "print(\"Average tasks per dataset:\", n_tasks.sum() / len(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2), dpi=200)\n",
    "plt.hist(samples, bins=[i for i in range(0, 201, 10)], color=\"deepskyblue\", rwidth=0.85, edgecolor=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Number of datasets\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac95a6",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(info_path=\"../data/GEO_v2/training_data_v2.csv\",\n",
    "               column_path=\"../data/GEO_v2/training_columns.txt\",\n",
    "               path_prefix=\"../\", normalize_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521972a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training datasets:\", data._data_train[\"name\"].nunique())\n",
    "print(\"Training tasks:\", len(data._data_train))\n",
    "print(\"Training samples:\", data._data_train.groupby(\"name\")[\"sample_count\"].mean().sum())\n",
    "print(\"Testing datasets:\", data._data_test[\"name\"].nunique())\n",
    "print(\"Testing tasks:\", len(data._data_test))\n",
    "print(\"Testing samples:\", data._data_test.groupby(\"name\")[\"sample_count\"].mean().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f460ef9",
   "metadata": {},
   "source": [
    "# Dataset table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dcaca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest = pd.read_csv(\"../data/GEO_v2/training_data_v3.csv\")\n",
    "traintest[\"pubmed_id\"] = traintest[\"pubmed_id\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8218bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = traintest.groupby(\"name\")\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    if i % 24 == 0:\n",
    "        if i > 0:\n",
    "            print(\"\\\\bottomrule\\n\\\\end{tabular}\")\n",
    "        print(\"\\\\begin{tabular}[t]{lrrr}\")\n",
    "        print(\"\\\\toprule\\nName & N & A & T \\\\\\\\\\n\\\\midrule\")\n",
    "    group = group.reset_index(drop=True)\n",
    "    print(f\"{name} & {group['sample_count'][0]} & {len(group)} & {'1' if group['is_train'][0] else '0'}\\\\\\\\\")\n",
    "print(\"\\\\bottomrule\\n\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42980de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = traintest.sort_values(\"sample_count\", inplace=False)\n",
    "\n",
    "sample_count_train = list()\n",
    "sample_count_test = list()\n",
    "\n",
    "groups = tmp.groupby(\"name\", sort=False)\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    if i % 24 == 0:\n",
    "        if i > 0:\n",
    "            print(\"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\quad\")\n",
    "        print(\"\\\\begin{tabular}[t]{lrr}\")\n",
    "        print(\"\\\\toprule\\nName & N & A\\\\\\\\\\n\\\\midrule\")\n",
    "    group = group.reset_index(drop=True)\n",
    "    if group['is_train'][0]:\n",
    "        print(f\"\\\\textbf{{{name}}} & {group['sample_count'][0]} & {len(group)}\\\\\\\\\")\n",
    "        sample_count_train.append(group['sample_count'][0])\n",
    "    else:\n",
    "        print(f\"{name} & {group['sample_count'][0]} & {len(group)}\\\\\\\\\")\n",
    "        sample_count_test.append(group['sample_count'][0])\n",
    "print(\"\\\\bottomrule\\n\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_count_train+sample_count_test, bins=[i for i in range(50, 201, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = traintest[traintest[\"is_train\"]].groupby('name')\n",
    "print((group[\"sample_count\"].sum() / group.count()[\"sample_count\"]).sum())\n",
    "print(traintest[\"is_train\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69f240",
   "metadata": {},
   "source": [
    "# Results (OLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a354a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open default test results from TEST data\n",
    "default_results = pd.read_csv(\"../data/GEO_v2/test_default.csv\")\n",
    "\n",
    "# open traintest split\n",
    "dataset = Dataset(path_prefix=\"../\")\n",
    "\n",
    "dr_l1000 = default_results[default_results[\"input\"] == \"L1000\"]\n",
    "dr_l1000 = dr_l1000[dr_l1000[\"name\"].isin(dataset._data_test[\"name\"].unique())]\n",
    "del dataset\n",
    "\n",
    "dr_l1000 = dr_l1000.reset_index(drop=True)\n",
    "\n",
    "METRIC_COLS = [\"neg_log_loss\", \"f1\", \"precision\", \"recall\", \"roc_auc\", \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"MultiTask\" # AutoEncoder, MultiTask, AttentionMultiTask\n",
    "\n",
    "print(MODEL_TYPE)\n",
    "model_names = [name for name in os.listdir(f\"../models/GEO_v2/{MODEL_TYPE}\")\n",
    "               if os.path.isdir(f\"../models/GEO_v2/{MODEL_TYPE}/{name}\") and name.endswith(\"-1024\")]\n",
    "print(f\"{len(model_names)} model test results loaded\")\n",
    "\n",
    "# read data as mean and as diff to default results\n",
    "tmp_dr_l1000 = pd.DataFrame(np.repeat(dr_l1000.values, 2, axis=0))\n",
    "tmp_dr_l1000.columns = dr_l1000.columns\n",
    "\n",
    "tmp_mean = None\n",
    "tmp_diff = None\n",
    "for model_name in tqdm(model_names):\n",
    "    test_results = pd.read_csv(f\"../models/GEO_v2/{MODEL_TYPE}/{model_name}/test.csv\")\n",
    "    if \"_\" in model_name:\n",
    "        test_results[\"num_heads\"] = model_name.split(\"_\")[-1]\n",
    "        model_name = model_name.split(\"_\")[0]\n",
    "    test_results[\"hidden_size\"] = model_name.split(\"-\")[-1]\n",
    "    \n",
    "    # mean\n",
    "    if tmp_mean is not None:\n",
    "        tmp_mean[METRIC_COLS] = tmp_mean[METRIC_COLS] + test_results[METRIC_COLS]\n",
    "    else:\n",
    "        tmp_mean = test_results.copy()\n",
    "\n",
    "    # diff\n",
    "    test_results[METRIC_COLS] -= tmp_dr_l1000[METRIC_COLS]\n",
    "    if tmp_diff is not None:\n",
    "        tmp_diff = pd.concat([tmp_diff, test_results]).reset_index(drop=True)\n",
    "    else:\n",
    "        tmp_diff = test_results\n",
    "\n",
    "tmp_mean[METRIC_COLS] /= len(model_names)\n",
    "test_results_mean = tmp_mean\n",
    "test_results_diff = tmp_diff\n",
    "del tmp_mean, tmp_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80863022",
   "metadata": {},
   "source": [
    "### distribution of differences between test results and baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57d42a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BW_ADJUST = 1\n",
    "SAVE = False\n",
    "\n",
    "os.makedirs(f\"../literature/meetings/{MODEL_TYPE}-16\", exist_ok=True)\n",
    "\n",
    "for X in METRIC_COLS:\n",
    "    plt.figure()\n",
    "    sns.kdeplot(\n",
    "        data=test_results_diff, x=X, hue=\"input\",\n",
    "        bw_adjust=BW_ADJUST, common_norm=False, fill=True, alpha=0.2\n",
    "    )\n",
    "    if X == \"neg_log_loss\":\n",
    "        plt.xlim(-6, 5)\n",
    "    else:\n",
    "        plt.xlim(-1.2, 1.2)\n",
    "        plt.ylim(0, 10)\n",
    "    if SAVE:\n",
    "        plt.savefig(f\"../literature/meetings/{MODEL_TYPE}-1024/diff_{X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd5af4",
   "metadata": {},
   "source": [
    "### probability of difference being positive/equal/negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57e16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "\n",
    "os.makedirs(f\"../figures/results/{MODEL_TYPE}\", exist_ok=True)\n",
    "\n",
    "def plot_text(values, bottom=None):\n",
    "    if bottom is None:\n",
    "        bottom = [0 for _ in values]\n",
    "    for i, (val, btm) in enumerate(zip(values, bottom)):\n",
    "        if val == 0:\n",
    "            continue\n",
    "        to_print = f\"{val:.2f}\"\n",
    "        offset = 0.25 if len(to_print) == 5 else (1/6 if len(to_print) == 4 else 1/3)\n",
    "        plt.text(i-offset, val/2+btm, to_print)\n",
    "\n",
    "for INPUT in [\"encoded\", \"combined\"]:\n",
    "    prob_low = list()\n",
    "    prob_med = list()\n",
    "    prob_hi = list()\n",
    "\n",
    "    for MCOL in METRIC_COLS:\n",
    "        values = test_results_diff[test_results_diff[\"input\"] == INPUT][MCOL].to_numpy()\n",
    "        bs_sample = np.random.choice(values, size=values.shape[0], replace=True)\n",
    "        _len = values.shape[0]\n",
    "        prob_low.append((bs_sample < 0).sum()*100/_len)\n",
    "        prob_med.append((bs_sample == 0).sum()*100/_len)\n",
    "        prob_hi.append((bs_sample > 0).sum()*100/_len)\n",
    "\n",
    "    prob_low = np.array(prob_low)\n",
    "    prob_med = np.array(prob_med)\n",
    "    prob_hi = np.array(prob_hi)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(METRIC_COLS, prob_low, color=\"tab:red\", label=\"Lower\")\n",
    "    plot_text(prob_low)\n",
    "    plt.bar(METRIC_COLS, prob_med, color=\"tab:orange\", bottom=prob_low, label=\"Equal\")\n",
    "    plot_text(prob_med, bottom=prob_low)\n",
    "    plt.bar(METRIC_COLS, prob_hi, color=\"tab:green\", bottom=prob_low+prob_med, label=\"Higher\")\n",
    "    plot_text(prob_hi, bottom=prob_low+prob_med)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    if SAVE:\n",
    "        plt.savefig(f\"../literature/meetings/{MODEL_TYPE}-16/diff_prob_{INPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee0879",
   "metadata": {},
   "source": [
    "### distribution of raw test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1f880",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BW_ADJUST = 0.25\n",
    "SAVE = False\n",
    "\n",
    "os.makedirs(f\"../figures/results/{MODEL_TYPE}\", exist_ok=True)\n",
    "\n",
    "for X in METRIC_COLS:\n",
    "    plt.figure()\n",
    "    ax = sns.kdeplot(\n",
    "        data=pd.concat([test_results_mean, dr_l1000]).reset_index(), x=X, hue=\"input\",\n",
    "        bw_adjust=BW_ADJUST, common_norm=False, fill=True, alpha=0.2\n",
    "    )\n",
    "    if X == \"neg_log_loss\":\n",
    "        sns.move_legend(ax, loc=\"upper right\")\n",
    "    else:\n",
    "        sns.move_legend(ax, loc=\"upper left\")\n",
    "    if SAVE:\n",
    "        plt.savefig(f\"../literature/meetings/{MODEL_TYPE}-1024/mean_{X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f11843",
   "metadata": {},
   "source": [
    "### plot results with regard to latent layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab56175",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "INPUT = \"combined\"\n",
    "\n",
    "os.makedirs(f\"../figures/results/{MODEL_TYPE}\", exist_ok=True)\n",
    "\n",
    "for X in METRIC_COLS:\n",
    "    plt.figure()\n",
    "    sns.kdeplot(\n",
    "        data=test_results_diff[test_results_diff[\"input\"] == INPUT], x=X, hue=\"hidden_size\",\n",
    "        bw_adjust=0.5, common_norm=False, fill=False\n",
    "    )\n",
    "    \n",
    "    if X != \"neg_log_loss\":\n",
    "        plt.ylim(0, 2)\n",
    "        #plt.xlim(-1, 1)\n",
    "    if SAVE:\n",
    "        plt.savefig(f\"../figures/results/{MODEL_TYPE}/diff_hidden_size_{INPUT}_{X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b97397",
   "metadata": {},
   "source": [
    "### plot results with regard to latent number of heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6fbb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "INPUT = \"encoded\"\n",
    "\n",
    "os.makedirs(f\"../figures/results/{MODEL_TYPE}\", exist_ok=True)\n",
    "\n",
    "for X in METRIC_COLS:\n",
    "    plt.figure()\n",
    "    sns.kdeplot(\n",
    "        data=test_results_diff[test_results_diff[\"input\"] == INPUT], x=X, hue=\"num_heads\",\n",
    "        bw_adjust=0.5, common_norm=False, fill=False\n",
    "    )\n",
    "    plt.ylim(0, 5)\n",
    "    if SAVE:\n",
    "        plt.savefig(f\"../figures/results/{MODEL_TYPE}/diff_num_heads_{INPUT}_{X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f4cc1",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16149f07",
   "metadata": {},
   "source": [
    "## Plot training results for a model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b6beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE = \"MultiTask\" # AutoEncoder MultiTask\n",
    "\n",
    "METRIC = \"train_loss\" # train_loss, train_alt_loss, train_time, val_loss, val_alt_loss, val_time, time\n",
    "YLABEL = \"log loss\" # MSE loss, $ R^{2} $, log loss, AUC\n",
    "YLIMIT = (0.25, 0.70) # (80, 400) for MSE, (0.94, 0.99) for R^2, (0.25, 0.70) for log loss, (0.50, 0.92) for AUC\n",
    "\n",
    "SAVEFIG = False\n",
    "\n",
    "SIZES = [4, 5, 6, 7, 8, 10, 12, 16, 32, 64]\n",
    "COLORS = list(mcolors.TABLEAU_COLORS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6ce173",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframes = dict()\n",
    "for size in SIZES:\n",
    "    tmp_list = list()\n",
    "    for i in range(10):\n",
    "        tmp_list.append(pd.read_csv(f\"../models/{ARCHITECTURE}/{size}/{i}/train.csv\"))\n",
    "    train_dataframes[size] = tmp_list\n",
    "del tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ae91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table with train, val results\n",
    "loss_str = list()\n",
    "alt_loss_str = list()\n",
    "time_str = list()\n",
    "epoch_str = list()\n",
    "\n",
    "for size in SIZES:\n",
    "    train_loss, train_alt_loss, train_time, val_loss, val_alt_loss, val_time = list(), list(), list(), list(), list(), list()\n",
    "    epoch_num = list()\n",
    "    for td in train_dataframes[size]:\n",
    "        train_loss.append(td[\"train_loss\"].tolist()[-1])\n",
    "        train_alt_loss.append(td[\"train_alt_loss\"].tolist()[-1])\n",
    "        train_time.extend(td[\"train_time\"].tolist())\n",
    "        val_loss.append(td[\"val_loss\"].tolist()[-1])\n",
    "        val_alt_loss.append(td[\"val_alt_loss\"].tolist()[-1])\n",
    "        val_time.extend(td[\"val_time\"].tolist())\n",
    "        epoch_num.append(td.shape[0])\n",
    "        \"\"\" if size == 64:\n",
    "            print(f\"{np.mean(td['train_time'].tolist()):.4f} {np.std(td['train_time'].tolist()):.4f}\")\n",
    "            print(f\"{np.mean(td['val_time'].tolist()):.4f} {np.std(td['val_time'].tolist()):.4f}\") \"\"\"\n",
    "    loss_str.append((\n",
    "        fr\"{size} & \"\n",
    "        fr\"{np.mean(train_loss):.3f} $ \\pm $ {np.std(train_loss):.3f} & \"\n",
    "        fr\"{np.mean(val_loss):.3f} $ \\pm $ {np.std(val_loss):.3f} \\\\\"\n",
    "    ))\n",
    "    alt_loss_str.append((\n",
    "        fr\"{size} & \"\n",
    "        fr\"{np.mean(train_alt_loss):.3f} $ \\pm $ {np.std(train_alt_loss):.3f} & \"\n",
    "        fr\"{np.mean(val_alt_loss):.3f} $ \\pm $ {np.std(val_alt_loss):.3f} \\\\\"\n",
    "    ))\n",
    "    time_str.append((\n",
    "        fr\"{size} & \"\n",
    "        fr\"{np.mean(train_time):.3f} $ \\pm $ {np.std(train_time):.3f} & \"\n",
    "        fr\"{np.mean(val_time):.3f} $ \\pm $ {np.std(val_time):.3f} \\\\\"\n",
    "    ))\n",
    "    epoch_str.append((\n",
    "        fr\"{size} & \"\n",
    "        fr\"{np.mean(epoch_num):.1f} $ \\pm $ {np.std(epoch_num):.1f} \\\\\"\n",
    "    ))\n",
    "print(\"Loss\")\n",
    "print(\"\\n\".join(loss_str))\n",
    "print(\"Alt Loss\")\n",
    "print(\"\\n\".join(alt_loss_str))\n",
    "print(\"Time\")\n",
    "print(\"\\n\".join(time_str))\n",
    "print(\"Epoch\")\n",
    "print(\"\\n\".join(epoch_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07093625",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "l = r = 0\n",
    "\n",
    "# print(\"AUTOENCODERS\")\n",
    "# \n",
    "# print(\"32 vs 64 MSE train\")\n",
    "# l = np.random.normal(112.8, 0.9, N) # 32\n",
    "# r = np.random.normal(111.6, 4.0, N) # 64\n",
    "# print((l > r).sum() / N)\n",
    "# \n",
    "# print(\"32 vs 64 MSE val\")\n",
    "# l = np.random.normal(137.2, 1.0, N) # 32\n",
    "# r = np.random.normal(135.1, 3.3, N) # 64\n",
    "# print((l > r).sum() / N)\n",
    "# \n",
    "# print(\"32 vs 64 R^2 train\")\n",
    "# l = np.random.normal(0.9849, 0.0007, N) # 32\n",
    "# r = np.random.normal(0.9850, 0.0006, N) # 64\n",
    "# print((l < r).sum() / N)\n",
    "# \n",
    "# print(\"32 vs 64 R^2 val\")\n",
    "# l = np.random.normal(0.9828, 0.0003, N) # 32\n",
    "# r = np.random.normal(0.9831, 0.0006, N) # 64\n",
    "# print((l < r).sum() / N)\n",
    "\n",
    "# print(\"MULTITASK\")\n",
    "# print(\"16 vs 64 log loss train\")\n",
    "# #l = np.random.normal(0.340, 0.025, N) # 12\n",
    "# l = np.random.normal(0.339, 0.016, N) # 16\n",
    "# r = np.random.normal(0.322, 0.014, N) # 64\n",
    "# print((l > r).sum() / N)\n",
    "# print(\"12 vs 16 log loss val\")\n",
    "# l = np.random.normal(0.408, 0.012, N) # 12\n",
    "# r = np.random.normal(0.406, 0.008, N) # 16\n",
    "# print((l > r).sum() / N)\n",
    "# print(\"32 vs 64 AUC train\")\n",
    "# l = np.random.normal(0.859, 0.015, N) # 32\n",
    "# r = np.random.normal(0.873, 0.013, N) # 64\n",
    "# print((l < r).sum() / N)\n",
    "# print(\"32 vs 16 AUC val\")\n",
    "# l = np.random.normal(0.800, 0.016, N) # 32\n",
    "# r = np.random.normal(0.816, 0.010, N) # 16\n",
    "# print((l < r).sum() / N)\n",
    "\n",
    "# print(\"Autoencoder train times\")\n",
    "# times = np.random.normal(\n",
    "#     #    4      5      6      7      8     10     12     16     32     64\n",
    "#     [0.286, 0.283, 0.283, 0.286, 0.282, 0.285, 0.283, 0.281, 1.310, 0.442],\n",
    "#     [0.025, 0.023, 0.021, 0.025, 0.023, 0.025, 0.025, 0.025, 0.408, 0.152],\n",
    "#     (N, 10)\n",
    "# )\n",
    "# _, COUNTS = np.unique(np.argmin(times, axis=1), return_counts=True)\n",
    "# for s, c in zip(SIZES, COUNTS):\n",
    "#     print(f\"{s}: {c/N*100:.1f}%\")\n",
    "# \n",
    "# print(\"Autoencoder validation times\")\n",
    "# times = np.random.normal(\n",
    "#     #    4      5      6      7      8     10     12     16     32     64\n",
    "#     [0.012, 0.012, 0.012, 0.012, 0.012, 0.012, 0.012, 0.012, 0.016, 0.015],\n",
    "#     [0.001, 0.001, 0.001, 0.001, 0.002, 0.001, 0.001, 0.002, 0.004, 0.004],\n",
    "#     (N, 10)\n",
    "# )\n",
    "# _, COUNTS = np.unique(np.argmin(times, axis=1), return_counts=True)\n",
    "# for s, c in zip(SIZES, COUNTS):\n",
    "#     print(f\"{s}: {c/N*100:.1f}%\")\n",
    "\n",
    "print(\"Multitask train times\")\n",
    "times = np.random.normal(\n",
    "    #    4      5      6      7      8     10     12     16     32     64\n",
    "    [0.257, 0.250, 0.255, 0.248, 0.252, 0.247, 0.248, 0.249, 0.254, 0.253],\n",
    "    [0.023, 0.017, 0.019, 0.019, 0.023, 0.017, 0.016, 0.020, 0.021, 0.051],\n",
    "    (N, 10)\n",
    ")\n",
    "_, COUNTS = np.unique(np.argmin(times, axis=1), return_counts=True)\n",
    "for s, c in zip(SIZES, COUNTS):\n",
    "    print(f\"{s}: {c/N*100:.1f}%\")\n",
    "\n",
    "print(\"Multitask validation times\")\n",
    "times = np.random.normal(\n",
    "    #    4      5      6      7      8     10     12     16     32     64\n",
    "    [0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013],\n",
    "    [0.002, 0.001, 0.001, 0.001, 0.002, 0.001, 0.001, 0.002, 0.002, 0.001],\n",
    "    (N, 10)\n",
    ")\n",
    "_, COUNTS = np.unique(np.argmin(times, axis=1), return_counts=True)\n",
    "for s, c in zip(SIZES, COUNTS):\n",
    "    print(f\"{s}: {c/N*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.argmin(times, axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac538dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "l = np.random.normal(135.1, 3.3, N)\n",
    "p = l / 884\n",
    "print(f\"{p.mean():.4f} $ \\pm $ {p.std():.4f}\")\n",
    "p = np.sqrt(p)\n",
    "print(f\"{p.mean():.4f} $ \\pm $ {p.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7863ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "l = np.random.normal(0.507, 0.064, N)\n",
    "p = np.exp(-l)\n",
    "print(f\"{p.mean():.4f} $ \\pm $ {p.std():.4f}\")\n",
    "l = np.random.normal(0.406, 0.008, N)\n",
    "p = np.exp(-l)\n",
    "print(f\"{p.mean():.4f} $ \\pm $ {p.std():.4f}\")\n",
    "del l, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(884*512 + 512*512 + 512*4 + 4*92)\n",
    "print(884*512 + 512*512 + 512*64 + 64*92)\n",
    "print((884*512 + 512*512 + 512*4) * 2)\n",
    "print((884*512 + 512*512 + 512*64) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da971a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot each model's train data as is, so they overlap\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    plt.clf()\n",
    "    for td in train_dataframes[size]:\n",
    "        plt.plot(td[METRIC], color=color, alpha=1)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(YLABEL)\n",
    "    plt.ylim(YLIMIT)\n",
    "    plt.tight_layout()\n",
    "    if True:\n",
    "        plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_{size}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e33b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate the results for each model into one line with errors\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    train_data = [np.zeros(1)] + list(td[METRIC].to_numpy() for td in train_dataframes[size])\n",
    "    train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "    indices = np.argsort(train_lengths)\n",
    "\n",
    "    x = np.arange(train_lengths[indices[-1]])\n",
    "    y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    #err = np.zeros((2, train_lengths[indices[-1]]), dtype=np.float32)\n",
    "    for i in range(len(indices)-1):\n",
    "        # construct Y matrix\n",
    "        Y = list()\n",
    "        for j in indices[i+1:]:\n",
    "            Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "        Y = np.array(Y)\n",
    "        # calculate mean and std\n",
    "        y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "        err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "        #err[0, train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.min(axis=0)\n",
    "        #err[1, train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.max(axis=0)\n",
    "    plt.errorbar(x[1:], y[1:], err[1:], color=color, alpha=0.5)\n",
    "    #plt.plot(x[1:], y[1:], color=color, label=size)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "    # IDEA: use ax.fill_between instead of errorbar\n",
    "\n",
    "    print(size, err[1:200].std())\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(YLABEL)\n",
    "plt.ylim(YLIMIT)\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_errorbar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate the results for each model into one line with errors\n",
    "- display only every x-th errorbar for visibility purposes\n",
    "\"\"\"\n",
    "\n",
    "ERROR_DISPLAY_DISTANCE = 10  # x from above\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    train_data = [np.zeros(1)] + list(td[METRIC].to_numpy() for td in train_dataframes[size])\n",
    "    train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "    indices = np.argsort(train_lengths)\n",
    "\n",
    "    x = np.arange(train_lengths[indices[-1]])\n",
    "    y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    #err = np.zeros((2, train_lengths[indices[-1]]), dtype=np.float32)\n",
    "    for i in range(len(indices)-1):\n",
    "        # construct Y matrix\n",
    "        Y = list()\n",
    "        for j in indices[i+1:]:\n",
    "            Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "        Y = np.array(Y)\n",
    "        # calculate mean and std\n",
    "        y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "        err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "        #err[0, train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.min(axis=0)\n",
    "        #err[1, train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.max(axis=0)\n",
    "    # calculate indices at which to display error\n",
    "    err_display_idx = np.arange((err.shape[0]//ERROR_DISPLAY_DISTANCE)) * ERROR_DISPLAY_DISTANCE\n",
    "    new_err = np.zeros(err.shape)\n",
    "    new_err[err_display_idx] = err[err_display_idx]\n",
    "\n",
    "    plt.errorbar(x[1:], y[1:], new_err[1:], color=color, alpha=0.7)\n",
    "    #plt.plot(x[1:], y[1:], color=color, label=size)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(YLABEL)\n",
    "plt.ylim(YLIMIT)\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_errorbar_10th.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    train_data = [np.zeros(1)] + list(td[METRIC].to_numpy() for td in train_dataframes[size])\n",
    "    train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "    indices = np.argsort(train_lengths)\n",
    "\n",
    "    x = np.arange(train_lengths[indices[-1]])\n",
    "    y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    for i in range(len(indices)-1):\n",
    "        # construct Y matrix\n",
    "        Y = list()\n",
    "        for j in indices[i+1:]:\n",
    "            Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "        Y = np.array(Y)\n",
    "        # calculate mean and std\n",
    "        y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "        err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "    plt.plot(x[1:], y[1:], color=color)\n",
    "    plt.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(YLABEL)\n",
    "plt.ylim(YLIMIT)\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_fill_between.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4 plots - AUTOENCODER\n",
    "\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "if ARCHITECTURE == \"AutoEncoder\":\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(9, 6), dpi=200)\n",
    "\n",
    "    for ax, metric, ylim in zip(\n",
    "        [ax1, ax3, ax2, ax4],\n",
    "        [\"train_loss\", \"train_alt_loss\", \"val_loss\", \"val_alt_loss\"],\n",
    "        [(80, 400), (0.94, 0.99), (80, 400), (0.94, 0.99)]\n",
    "    ):\n",
    "        for size, color in zip(SIZES, COLORS):\n",
    "            train_data = [np.zeros(1)] + list(td[metric].to_numpy() for td in train_dataframes[size])\n",
    "            train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "            indices = np.argsort(train_lengths)\n",
    "\n",
    "            x = np.arange(train_lengths[indices[-1]])\n",
    "            y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            for i in range(len(indices)-1):\n",
    "                # construct Y matrix\n",
    "                Y = list()\n",
    "                for j in indices[i+1:]:\n",
    "                    Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "                Y = np.array(Y)\n",
    "                # calculate mean and std\n",
    "                y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "                err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "            ax.plot(x[1:], y[1:], color=color)\n",
    "            ax.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "            ax.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "        ax.set_ylim(*ylim)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.grid(axis=\"y\", alpha=0.5)\n",
    "\n",
    "\n",
    "    ax4.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 1.2), framealpha=0.5, edgecolor=\"black\")\n",
    "\n",
    "    ax1.set_title(\"Train data\")\n",
    "    ax1.set_ylabel(\"MSE loss\")\n",
    "    ax2.set_title(\"Validation data\")\n",
    "    ax2.set_ylabel(\"MSE loss\")\n",
    "    ax3.set_title(\"Train data\")\n",
    "    ax3.set_ylabel(\"$ R^{2} $\")\n",
    "    ax4.set_title(\"Validation data\")\n",
    "    ax4.set_ylabel(\"$ R^{2} $\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "    # plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_fill_between.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4 plots - MULTITASK\n",
    "\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "if ARCHITECTURE == \"MultiTask\":\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(9, 6), dpi=200)\n",
    "\n",
    "    for ax, metric in zip(\n",
    "        [ax1, ax3, ax2, ax4],\n",
    "        [\"train_loss\", \"val_loss\", \"train_loss\", \"val_loss\"]\n",
    "    ):\n",
    "        for size, color in zip(SIZES, COLORS):\n",
    "            if size > 7 and (ax is ax1 or ax is ax2):\n",
    "                continue\n",
    "            if size <= 7 and (ax is ax3 or ax is ax4):\n",
    "                continue\n",
    "            train_data = [np.zeros(1)] + list(td[metric].to_numpy() for td in train_dataframes[size])\n",
    "            train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "            indices = np.argsort(train_lengths)\n",
    "\n",
    "            x = np.arange(train_lengths[indices[-1]])\n",
    "            y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            for i in range(len(indices)-1):\n",
    "                # construct Y matrix\n",
    "                Y = list()\n",
    "                for j in indices[i+1:]:\n",
    "                    Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "                Y = np.array(Y)\n",
    "                # calculate mean and std\n",
    "                y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "                err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "            ax.plot(x[1:], y[1:], color=color)\n",
    "            ax.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "            ax.plot([0, 0], [0, 0], color=color, alpha=1)\n",
    "\n",
    "        ax.set_ylim(0.25, 0.70)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.grid(axis=\"y\", alpha=0.5)\n",
    "\n",
    "    for size, color in zip(SIZES, COLORS):\n",
    "        if size > 7:\n",
    "            break\n",
    "        ax2.plot([0, 0], [0, 0], color=color, label=size)\n",
    "    ax2.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5), framealpha=0.5, edgecolor=\"black\")\n",
    "    for size, color in zip(SIZES, COLORS):\n",
    "        if size <= 7:\n",
    "            continue\n",
    "        ax4.plot([0, 0], [0, 0], color=color, label=size)\n",
    "    ax4.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5), framealpha=0.5, edgecolor=\"black\")\n",
    "\n",
    "    ax1.set_title(\"Train data\")\n",
    "    ax1.set_ylabel(\"Log loss\")\n",
    "    ax2.set_title(\"Validation data\")\n",
    "    ax2.set_ylabel(\"Log loss\")\n",
    "    ax3.set_title(\"Train data\")\n",
    "    ax3.set_ylabel(\"Log loss\")\n",
    "    ax4.set_title(\"Validation data\")\n",
    "    ax4.set_ylabel(\"Log loss\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "    # plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_fill_between_logloss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4 plots - MULTITASK\n",
    "\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "if ARCHITECTURE == \"MultiTask\":\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(9, 6), dpi=200)\n",
    "\n",
    "    for ax, metric in zip(\n",
    "        [ax1, ax3, ax2, ax4],\n",
    "        [\"train_alt_loss\", \"val_alt_loss\", \"train_alt_loss\", \"val_alt_loss\"]\n",
    "    ):\n",
    "        for size, color in zip(SIZES, COLORS):\n",
    "            if size > 7 and (ax is ax1 or ax is ax2):\n",
    "                continue\n",
    "            if size <= 7 and (ax is ax3 or ax is ax4):\n",
    "                continue\n",
    "            train_data = [np.zeros(1)] + list(td[metric].to_numpy() for td in train_dataframes[size])\n",
    "            train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "            indices = np.argsort(train_lengths)\n",
    "\n",
    "            x = np.arange(train_lengths[indices[-1]])\n",
    "            y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            for i in range(len(indices)-1):\n",
    "                # construct Y matrix\n",
    "                Y = list()\n",
    "                for j in indices[i+1:]:\n",
    "                    Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "                Y = np.array(Y)\n",
    "                # calculate mean and std\n",
    "                y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "                err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "            ax.plot(x[1:], y[1:], color=color)\n",
    "            ax.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "            ax.plot([0, 0], [0, 0], color=color, alpha=1)\n",
    "\n",
    "        ax.set_ylim(0.50, 0.92)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.grid(axis=\"y\", alpha=0.5)\n",
    "\n",
    "    for size, color in zip(SIZES, COLORS):\n",
    "        ax4.plot([0, 0], [0, 0], color=color, label=size)\n",
    "    ax4.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 1.2), framealpha=0.5, edgecolor=\"black\")\n",
    "\n",
    "    ax1.set_title(\"Train data\")\n",
    "    ax1.set_ylabel(\"AUC\")\n",
    "    ax2.set_title(\"Validation data\")\n",
    "    ax2.set_ylabel(\"AUC\")\n",
    "    ax3.set_title(\"Train data\")\n",
    "    ax3.set_ylabel(\"AUC\")\n",
    "    ax4.set_title(\"Validation data\")\n",
    "    ax4.set_ylabel(\"AUC\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "    # plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_fill_between_auc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8 plots - MULTITASK\n",
    "\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\"\"\"\n",
    "if ARCHITECTURE == \"MultiTask\":\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(9, 12))\n",
    "\n",
    "    for ax, metric in zip(\n",
    "        [ax1, ax3, ax2, ax4],\n",
    "        [\"train_loss\", \"val_loss\", \"train_loss\", \"val_loss\"]\n",
    "    ):\n",
    "        for size, color in zip(SIZES, COLORS):\n",
    "            if size > 7 and (ax is ax1 or ax is ax2):\n",
    "                continue\n",
    "            if size <= 7 and (ax is ax3 or ax is ax4):\n",
    "                continue\n",
    "            train_data = [np.zeros(1)] + list(td[metric].to_numpy() for td in train_dataframes[size])\n",
    "            train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "            indices = np.argsort(train_lengths)\n",
    "\n",
    "            x = np.arange(train_lengths[indices[-1]])\n",
    "            y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            for i in range(len(indices)-1):\n",
    "                # construct Y matrix\n",
    "                Y = list()\n",
    "                for j in indices[i+1:]:\n",
    "                    Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "                Y = np.array(Y)\n",
    "                # calculate mean and std\n",
    "                y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "                err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "            ax.plot(x[1:], y[1:], color=color)\n",
    "            ax.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "            ax.plot([0, 0], [0, 0], color=color, alpha=1)\n",
    "\n",
    "        ax.set_ylim(0.25, 0.70)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.grid(axis=\"y\", alpha=0.5)\n",
    "\n",
    "    for ax, metric in zip(\n",
    "        [ax5, ax7, ax6, ax8],\n",
    "        [\"train_alt_loss\", \"val_alt_loss\", \"train_alt_loss\", \"val_alt_loss\"]\n",
    "    ):\n",
    "        for size, color in zip(SIZES, COLORS):\n",
    "            if size > 7 and (ax is ax5 or ax is ax6):\n",
    "                continue\n",
    "            if size <= 7 and (ax is ax7 or ax is ax8):\n",
    "                continue\n",
    "            train_data = [np.zeros(1)] + list(td[metric].to_numpy() for td in train_dataframes[size])\n",
    "            train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "            indices = np.argsort(train_lengths)\n",
    "\n",
    "            x = np.arange(train_lengths[indices[-1]])\n",
    "            y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "            for i in range(len(indices)-1):\n",
    "                # construct Y matrix\n",
    "                Y = list()\n",
    "                for j in indices[i+1:]:\n",
    "                    Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "                Y = np.array(Y)\n",
    "                # calculate mean and std\n",
    "                y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "                err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "            ax.plot(x[1:], y[1:], color=color)\n",
    "            ax.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "            ax.plot([0, 0], [0, 0], color=color, alpha=1)\n",
    "\n",
    "        ax.set_ylim(0.50, 0.92)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.grid(axis=\"y\", alpha=0.5)\n",
    "\n",
    "    for size, color in zip(SIZES, COLORS):\n",
    "        ax6.plot([0, 0], [0, 0], color=color, label=size)\n",
    "    ax6.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 1.2))\n",
    "\n",
    "    ax1.set_title(\"Train data\")\n",
    "    ax1.set_ylabel(\"Log loss\")\n",
    "    ax2.set_title(\"Validation data\")\n",
    "    ax2.set_ylabel(\"Log loss\")\n",
    "    ax3.set_title(\"Train data\")\n",
    "    ax3.set_ylabel(\"Log loss\")\n",
    "    ax4.set_title(\"Validation data\")\n",
    "    ax4.set_ylabel(\"Log loss\")\n",
    "    ax5.set_title(\"Train data\")\n",
    "    ax5.set_ylabel(\"AUC\")\n",
    "    ax6.set_title(\"Validation data\")\n",
    "    ax6.set_ylabel(\"AUC\")\n",
    "    ax7.set_title(\"Train data\")\n",
    "    ax7.set_ylabel(\"AUC\")\n",
    "    ax8.set_title(\"Validation data\")\n",
    "    ax8.set_ylabel(\"AUC\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "    # plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_fill_between.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212abe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate the results for each model into one line with shadows for errors\n",
    "\n",
    "For MultiTask models, plot lower encodings seperate from higher encodings (4-8 vs 10-64)\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    if ARCHITECTURE != \"MultiTask\":\n",
    "        print(f\"Architecture {ARCHITECTURE} is not meant to be run with this code!\")\n",
    "        break\n",
    "\n",
    "    train_data = [np.zeros(1)] + list(td[METRIC].to_numpy() for td in train_dataframes[size])\n",
    "    train_lengths = np.array([td.shape[0] for td in train_data])\n",
    "    indices = np.argsort(train_lengths)\n",
    "\n",
    "    x = np.arange(train_lengths[indices[-1]])\n",
    "    y = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    err = np.zeros(train_lengths[indices[-1]], dtype=np.float32)\n",
    "    for i in range(len(indices)-1):\n",
    "        # construct Y matrix\n",
    "        Y = list()\n",
    "        for j in indices[i+1:]:\n",
    "            Y.append(train_data[j][train_lengths[indices[i]]:train_lengths[indices[i+1]]])\n",
    "        Y = np.array(Y)\n",
    "        # calculate mean and std\n",
    "        y[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.mean(axis=0)\n",
    "        err[train_lengths[indices[i]]:train_lengths[indices[i+1]]] = Y.std(axis=0)\n",
    "    plt.plot(x[1:], y[1:], color=color)\n",
    "    plt.fill_between(x[1:], y[1:]-err[1:], y[1:]+err[1:], alpha=0.4, color=color)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "    if size == 7:\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(YLABEL)\n",
    "        plt.ylim(YLIMIT)\n",
    "        if SAVEFIG:\n",
    "            plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_fill_between_lower.png\")\n",
    "        plt.clf()\n",
    "    if size == 64:\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(YLABEL)\n",
    "        plt.ylim(YLIMIT)\n",
    "        if SAVEFIG:\n",
    "            plt.savefig(f\"../figures/results/train/{ARCHITECTURE}_{METRIC}_fill_between_upper.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05751e2a",
   "metadata": {},
   "source": [
    "## Plotting testing scatterplot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01eea75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open default test results from TEST data\n",
    "default_results = pd.read_csv(\"../data/GEO_v2/test_default_v3.csv\")\n",
    "\n",
    "# keep only raw, logistic regression results\n",
    "default_results = default_results[default_results[\"input\"] == \"L1000\"].reset_index(drop=True)\n",
    "\n",
    "# select only testing datasets\n",
    "dataset = Dataset(\n",
    "    info_path=\"../data/GEO_v2/training_data_v3.csv\",\n",
    "    column_path=\"../data/GEO_v2/training_columns.txt\",\n",
    "    path_prefix=\"../\"\n",
    ")\n",
    "TEST_GDS = set(dataset._data_test[\"name\"].unique().tolist())\n",
    "\n",
    "default_results = default_results[default_results[\"name\"].isin(TEST_GDS)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec849df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE = \"MultiTask\" # AutoEncoder MultiTask\n",
    "\n",
    "METRIC = \"roc_auc\" # neg_log_loss, f1, precision, recall, roc_auc, accuracy\n",
    "\n",
    "SAVEFIG = False\n",
    "\n",
    "SIZES = [4, 5, 6, 7, 8, 10, 12, 16, 32, 64]\n",
    "COLORS = list(mcolors.TABLEAU_COLORS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d46bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframes = dict()\n",
    "for size in SIZES:\n",
    "    tmp_list = list()\n",
    "    for i in range(10):\n",
    "        tmp_list.append(pd.read_csv(f\"../models/{ARCHITECTURE}/{size}/{i}/test.csv\"))\n",
    "    test_dataframes[size] = tmp_list\n",
    "del tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e692e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot each model's test data as is, so they overlap\n",
    "\"\"\"\n",
    "\n",
    "# diagonal line\n",
    "ax = plt.gca()\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\".5\", transform=ax.transAxes)\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    x_all = list()\n",
    "    y_all = list()\n",
    "    for td in test_dataframes[size]:\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        assert (encoded_td[\"name\"] == default_results[\"name\"]).all()\n",
    "        assert (encoded_td[\"target\"] == default_results[\"target\"]).all()\n",
    "        df = encoded_td.join(default_results, lsuffix=\"_encoded\", rsuffix=\"_l1000\")\n",
    "        x = df[f\"{METRIC}_l1000\"].to_numpy()\n",
    "        y = df[f\"{METRIC}_encoded\"].to_numpy()\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "\n",
    "        plt.scatter(x, y, marker=\".\", color=color, alpha=0.1)\n",
    "\n",
    "    x_all = np.array(x_all).flatten()\n",
    "    y_all = np.array(y_all).flatten()\n",
    "    line = stats.linregress(x_all, y_all)\n",
    "    ax.plot([0, 1], [line.intercept, line.intercept+line.slope], ls=\"-\", c=color, transform=ax.transAxes)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.xlabel(\"AUC on raw data\")\n",
    "plt.ylabel(\"AUC on encoded data\")\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_all_points.png\")\n",
    "    # plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_all_points.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bca17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 4, k=0.564 $\\pm$ 0.043, n=0.223 $\\pm$ 0.034\n",
      "Size: 5, k=0.611 $\\pm$ 0.045, n=0.195 $\\pm$ 0.035\n",
      "Size: 6, k=0.673 $\\pm$ 0.042, n=0.155 $\\pm$ 0.032\n",
      "Size: 7, k=0.692 $\\pm$ 0.041, n=0.153 $\\pm$ 0.032\n",
      "Size: 8, k=0.724 $\\pm$ 0.038, n=0.133 $\\pm$ 0.030\n",
      "Size: 10, k=0.755 $\\pm$ 0.037, n=0.115 $\\pm$ 0.029\n",
      "Size: 12, k=0.773 $\\pm$ 0.037, n=0.108 $\\pm$ 0.028\n",
      "Size: 16, k=0.804 $\\pm$ 0.037, n=0.090 $\\pm$ 0.029\n",
      "Size: 32, k=0.842 $\\pm$ 0.031, n=0.080 $\\pm$ 0.024\n",
      "Size: 64, k=0.888 $\\pm$ 0.027, n=0.050 $\\pm$ 0.021\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot each model's test data as is, so they overlap\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    x_all = default_results[METRIC].to_numpy()\n",
    "    y_all = list()\n",
    "    for td in test_dataframes[size]:\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        assert (encoded_td[\"name\"] == default_results[\"name\"]).all()\n",
    "        assert (encoded_td[\"target\"] == default_results[\"target\"]).all()\n",
    "        y = encoded_td[METRIC].to_numpy()\n",
    "        y_all.append(y)\n",
    "\n",
    "        #plt.scatter(x, y, marker=\".\", color=color, alpha=0.1)\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    x_all = np.array(x_all)\n",
    "    y_all = np.array(y_all)\n",
    "    plt.errorbar(x_all, y_all.mean(axis=0), y_all.std(axis=0), fmt=\".\", color=color)\n",
    "\n",
    "    # diagonal line\n",
    "    ax = plt.gca()\n",
    "    ax.plot([0, 1], [0, 1], ls=\"--\", c=\".5\", transform=ax.transAxes)\n",
    "\n",
    "    line = stats.linregress(x_all, y_all.mean(axis=0))\n",
    "    ax.plot([0, 1], [line.intercept, line.intercept+line.slope], ls=\"-\", c=color, transform=ax.transAxes)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "\n",
    "    print(f\"Size: {size}, k={line.slope:.3f} $\\pm$ {line.stderr:.3f}, n={line.intercept:.3f} $\\pm$ {line.intercept_stderr:.3f}\")\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.xlim(0.25, 1.05)\n",
    "    plt.ylim(0.25, 1.05)\n",
    "    plt.xlabel(\"AUC on raw data\")\n",
    "    plt.ylabel(\"AUC on encoded data\")\n",
    "    plt.title(f\"{size}-{ARCHITECTURE}\")\n",
    "    plt.text(\n",
    "        0.3, 0.95,\n",
    "        f\"$ y = {line.slope:.3f} x + {line.intercept:.3f} $\",\n",
    "        fontsize=12,\n",
    "        bbox={\"boxstyle\": \"round\", \"edgecolor\": color, \"facecolor\": \"white\"}\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    if SAVEFIG:\n",
    "        plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_errorbar_{size}.png\")\n",
    "        # plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_errorbar_{size}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6 plot - AUC-AUC\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(9, 11), dpi=200)\n",
    "\n",
    "for ax, size, architecture, name in zip(\n",
    "    [ax1, ax3, ax5, ax2, ax4, ax6],\n",
    "    [4, 8, 32, 6, 12, 64],\n",
    "    [\"AutoEncoder\", \"AutoEncoder\", \"AutoEncoder\", \"MultiTask\", \"MultiTask\", \"MultiTask\"],\n",
    "    [\"autoencoder\", \"autoencoder\", \"autoencoder\", \"multitask model\", \"multitask model\", \"multitask model\"]\n",
    "):\n",
    "    x_all = default_results[\"roc_auc\"].to_numpy()\n",
    "    y_all = list()\n",
    "    for i in range(10):\n",
    "        td = pd.read_csv(f\"../models/{architecture}/{size}/{i}/test.csv\")\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        assert (encoded_td[\"name\"] == default_results[\"name\"]).all()\n",
    "        assert (encoded_td[\"target\"] == default_results[\"target\"]).all()\n",
    "        y = encoded_td[\"roc_auc\"].to_numpy()\n",
    "        y_all.append(y)\n",
    "\n",
    "    color = COLORS[SIZES.index(size)]\n",
    "\n",
    "    x_all = np.array(x_all)\n",
    "    y_all = np.array(y_all)\n",
    "    ax.errorbar(x_all, y_all.mean(axis=0), y_all.std(axis=0), fmt=\".\", color=color, alpha=0.5)\n",
    "    ax.plot(x_all, y_all.mean(axis=0), \".\", color=color)\n",
    "    # diagonal line\n",
    "    ax.plot([0, 1], [0, 1], ls=\"--\", c=\".5\", transform=ax.transAxes)\n",
    "\n",
    "    line = stats.linregress(x_all, y_all.mean(axis=0))\n",
    "    ax.plot([0, 1], [line.intercept, line.intercept+line.slope], ls=\"-\", c=color, transform=ax.transAxes)\n",
    "\n",
    "    print(f\"Size: {size}, k={line.slope:.3f} $\\pm$ {line.stderr:.3f}, n={line.intercept:.3f} $\\pm$ {line.intercept_stderr:.3f}\")\n",
    "\n",
    "    ax.text(\n",
    "        0.3, 0.95,\n",
    "        f\"$ y = {line.slope:.3f} x + {line.intercept:.3f} $\",\n",
    "        fontsize=12,\n",
    "        bbox={\"boxstyle\": \"round\", \"edgecolor\": color, \"facecolor\": \"white\"}\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{size}-{name}\")\n",
    "    ax.set_xlim(0.25, 1.05)\n",
    "    ax.set_ylim(0.25, 1.05)\n",
    "    ax.set_xlabel(\"AUC on raw data\")\n",
    "    ax.set_ylabel(\"AUC on encoded data\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "# plt.savefig(f\"../figures/results/test/AUC_AUC_errorbar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b636ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "l = r = 0\n",
    "\n",
    "print(\"slope\")\n",
    "l = np.random.normal(0.888, 0.027, N)\n",
    "r = np.random.normal(0.873, 0.033, N)\n",
    "print((l > r).sum() / N)\n",
    "\n",
    "print(\"intercept\")\n",
    "l = np.random.normal(0.050, 0.021, N)\n",
    "r = np.random.normal(0.059, 0.025, N)\n",
    "print((l < r).sum() / N)\n",
    "\n",
    "l = np.random.normal(0.059, 0.027, N)\n",
    "r = np.random.normal(0.059, 0.025, N)\n",
    "print((l < r).sum() / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idnetify datasets with interesting results:\n",
    "# 1: good baseline, worse encoded\n",
    "# 2: bad baseline, better encoded\n",
    "\n",
    "x_all = default_results[METRIC].to_numpy()\n",
    "names_list = np.array([f\"{row['name']}-{row['target']}\" for _, row in default_results.iterrows()])\n",
    "\n",
    "# 1. - autoencoder\n",
    "size = 4\n",
    "y_all = list()\n",
    "for td in test_dataframes[size]:\n",
    "    encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "    assert (encoded_td[\"name\"] == default_results[\"name\"]).all()\n",
    "    assert (encoded_td[\"target\"] == default_results[\"target\"]).all()\n",
    "    y = encoded_td[METRIC].to_numpy()\n",
    "    y_all.append(y)\n",
    "y_all = np.array(y_all)\n",
    "y_mean = y_all.mean(axis=0)\n",
    "print(\"1.\", names_list[(y_mean < 0.5) * (x_all > 0.9)])\n",
    "\n",
    "# 2. - autoencoder\n",
    "size = 64\n",
    "y_all = list()\n",
    "for td in test_dataframes[size]:\n",
    "    encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "    assert (encoded_td[\"name\"] == default_results[\"name\"]).all()\n",
    "    assert (encoded_td[\"target\"] == default_results[\"target\"]).all()\n",
    "    y = encoded_td[METRIC].to_numpy()\n",
    "    y_all.append(y)\n",
    "y_all = np.array(y_all)\n",
    "y_mean = y_all.mean(axis=0)\n",
    "print(\"2.\", names_list[(x_all < 0.35)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2857f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((x_all < 0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list[70:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af95ebd",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7270e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confusion matrix table\n",
    "\"\"\"\n",
    "\n",
    "for size in SIZES:\n",
    "    cmat = np.zeros((len(test_dataframes[size]), test_dataframes[size][0].shape[0]//2, 4)) # we remove 'combined'\n",
    "    for i, td in enumerate(test_dataframes[size]):\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        cmat[i, :, :] = encoded_td[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy()\n",
    "    names = encoded_td[\"name\"] # the last 'encoded_td' is ok\n",
    "    cmat_mean = cmat.mean(axis=0)\n",
    "    cmat_std = cmat.std(axis=0)\n",
    "    with open(f\"../figures/results/test/{ARCHITECTURE}_confusion_matrix_{size}.md\", \"w\") as f:\n",
    "        f.write(f\"# Confusion matrix - {ARCHITECTURE.upper()}\\n| Dataset name | TP | TN | FP | FN |\\n| --- | --- | --- | --- | --- |\\n\")\n",
    "        for n, m, s in zip(names, cmat_mean, cmat_std):\n",
    "            f.write(f\"| {n} | \")\n",
    "            f.write(\" | \".join(f\"{_m:.1f} $ \\pm $ {_s:.1f}\" for _m, _s in zip(m, s)))\n",
    "            f.write(\"|\\n\")\n",
    "    with open(f\"../figures/results/test/{ARCHITECTURE}_confusion_matrix_{size}.txt\", \"w\") as f:\n",
    "        f.write(f\"Dataset name & TP & TN & FP & FN \\\\\\\\\\n\")\n",
    "        for n, m, s in zip(names, cmat_mean, cmat_std):\n",
    "            f.write(f\"{n} & \")\n",
    "            f.write(\" & \".join(f\"{_m:.1f} $ \\pm $ {_s:.1f}\" for _m, _s in zip(m, s)))\n",
    "            f.write(\" \\\\\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37426a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Plot true-positive-rate vs true-negative-rate\n",
    "\"\"\"\n",
    "\n",
    "# baseline results\n",
    "tmp = default_results[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy().sum(axis=0)\n",
    "x = tmp[0] / (tmp[0] + tmp[3])\n",
    "y = tmp[1] / (tmp[1] + tmp[2])\n",
    "plt.scatter(x, y, s=5, c=\"k\")\n",
    "plt.plot([x, x], [y, y], color=\"k\", alpha=1, label=\"Baseline\")\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    cmat = np.zeros((len(test_dataframes[size]), 4)) # we remove 'combined'\n",
    "    for i, td in enumerate(test_dataframes[size]):\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        tmp = encoded_td[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy()\n",
    "        cmat[i, :] = tmp.sum(axis=0)\n",
    "\n",
    "    cmat_mean = cmat.mean(axis=0)\n",
    "    cmat_std = cmat.std(axis=0)\n",
    "    positive = cmat[0, 0] + cmat[0, 3]\n",
    "    negative = cmat[0, 1] + cmat[0, 2]\n",
    "    \n",
    "    x_mean = cmat_mean[0] / positive\n",
    "    x_std = cmat_std[0] / positive\n",
    "    y_mean = cmat_mean[1] / negative\n",
    "    y_std = cmat_std[1] / negative\n",
    "\n",
    "    print(f\"Size: {size}, tpr={x_mean:.3f} $\\pm$ {x_std:.3f} & tnr={y_mean:.3f} $\\pm$ {y_std:.3f}\")\n",
    "\n",
    "    plt.errorbar(x_mean, y_mean, xerr=x_std, yerr=y_std, fmt=\".\", color=color)\n",
    "    plt.plot([x_mean, x_mean], [y_mean, y_mean], color=color, alpha=1, label=size)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim(0.615, 0.665)\n",
    "plt.ylim(0.66, 0.92)\n",
    "plt.xlabel(\"True positive rate\")\n",
    "plt.ylabel(\"True negative rate\")\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_confusion_matrix.png\")\n",
    "    # plt.savefig(f\"../figures/results/test/{ARCHITECTURE}_confusion_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1336fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000_000\n",
    "l = r = 0\n",
    "\n",
    "l = np.random.normal(0.653, 0.007, N)  # 16-autoencoder\n",
    "r = np.random.normal(0.655, 0.004, N)  # 32-multitask\n",
    "print((l < r).sum() / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot true-positive-rate vs true-negative-rate\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4), dpi=200)\n",
    "\n",
    "tmp = default_results[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy().sum(axis=0)\n",
    "x = tmp[0] / (tmp[0] + tmp[3])\n",
    "y = tmp[1] / (tmp[1] + tmp[2])\n",
    "ax1.scatter(x, y, s=5, c=\"k\")\n",
    "ax2.scatter(x, y, s=5, c=\"k\")\n",
    "ax2.plot([0, 0], [0, 0], color=\"k\", alpha=1, label=\"Baseline\")\n",
    "\n",
    "for ax, architecture in zip(\n",
    "    [ax1, ax2],\n",
    "    [\"AutoEncoder\", \"MultiTask\"]\n",
    "):\n",
    "    for size, color in zip(SIZES, COLORS):\n",
    "        test_dataframes = list()\n",
    "        for i in range(10):\n",
    "            test_dataframes.append(pd.read_csv(f\"../models/{architecture}/{size}/{i}/test.csv\"))\n",
    "\n",
    "        cmat = np.zeros((len(test_dataframes), 4)) # we remove 'combined'\n",
    "        for i, td in enumerate(test_dataframes):\n",
    "            encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "            tmp = encoded_td[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy()\n",
    "            cmat[i, :] = tmp.sum(axis=0)\n",
    "\n",
    "        cmat_mean = cmat.mean(axis=0)\n",
    "        cmat_std = cmat.std(axis=0)\n",
    "        positive = cmat[0, 0] + cmat[0, 3]\n",
    "        negative = cmat[0, 1] + cmat[0, 2]\n",
    "        \n",
    "        x_mean = cmat_mean[0] / positive\n",
    "        x_std = cmat_std[0] / positive\n",
    "        y_mean = cmat_mean[1] / negative\n",
    "        y_std = cmat_std[1] / negative\n",
    "\n",
    "        ax.errorbar(x_mean, y_mean, xerr=x_std, yerr=y_std, fmt=\".\", color=color)\n",
    "        ax.plot([x_mean, x_mean], [y_mean, y_mean], color=color, alpha=1)\n",
    "\n",
    "        print(f\"{size} & {x_mean:.3f} $ \\pm $ {x_std:.3f} & {y_mean:.3f} $ \\pm $ {y_std:.3f} \\\\\\\\\")\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    ax2.plot([0, 0], [0, 0], c=color, label=size)\n",
    "ax2.legend(title=\"Size\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5), framealpha=0.5, edgecolor=\"black\")\n",
    "\n",
    "ax1.grid(alpha=0.5)\n",
    "ax2.grid(alpha=0.5)\n",
    "\n",
    "ax1.set_xlim(0.615, 0.665)\n",
    "ax2.set_xlim(0.615, 0.665)\n",
    "ax1.set_ylim(0.66, 0.92)\n",
    "ax2.set_ylim(0.66, 0.92)\n",
    "ax1.set_xlabel(\"True positive rate\")\n",
    "ax2.set_xlabel(\"True positive rate\")\n",
    "ax1.set_ylabel(\"True negative rate\")\n",
    "ax2.set_ylabel(\"True negative rate\")\n",
    "ax1.set_title(\"Autoencoders\")\n",
    "ax2.set_title(\"Multi-task models\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "plt.savefig(f\"../figures/results/test/TPR_TNR_errorbar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parallel Coordinates Plot\n",
    "\"\"\"\n",
    "\n",
    "for size, color in zip(SIZES, COLORS):\n",
    "    cmat = np.zeros((len(test_dataframes[size]), 4)) # we remove 'combined'\n",
    "    for i, td in enumerate(test_dataframes[size]):\n",
    "        encoded_td = td[td[\"input\"] == \"encoded\"].reset_index(drop=True)\n",
    "        tmp = encoded_td[[\"true_positive\", \"true_negative\", \"false_positive\", \"false_negative\"]].to_numpy()\n",
    "        cmat[i, :] = tmp.sum(axis=0)\n",
    "\n",
    "    positive = cmat[0, 0] + cmat[0, 3]\n",
    "    negative = cmat[0, 1] + cmat[0, 2]\n",
    "\n",
    "    cmat /= [positive, negative, negative, positive]\n",
    "\n",
    "    plt.plot([0, 1, 2, 3], cmat.mean(axis=0))\n",
    "    plt.errorbar([0, 1, 2, 3], cmat.mean(axis=0), cmat.std(axis=0), fmt=\".\", color=color)\n",
    "    plt.plot([0, 0], [0, 0], color=color, alpha=1, label=size)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xticks([0, 1, 2, 3], [\"TP\", \"TN\", \"FP\", \"FN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88efecc",
   "metadata": {},
   "source": [
    "### Plotting encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807228aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../figures/results/encodings/explained_variance_ratio.pickle\", \"rb\") as f:\n",
    "    pca_variance = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c47edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZES = [4, 5, 6, 7, 8, 10, 12, 16, 32, 64]\n",
    "COLORS = list(mcolors.TABLEAU_COLORS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(pca_variance[\"raw\"] >= 0.01)[0][-1]+1)\n",
    "print(np.where(pca_variance[\"raw\"] >= 0.001)[0][-1]+1)\n",
    "print(np.where(pca_variance[\"raw\"] >= 0.0001)[0][-1]+1)\n",
    "print(np.where(pca_variance[\"raw\"] >= 0.00001)[0][-1]+1)\n",
    "print(pca_variance[\"raw\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d89ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum table\n",
    "raw_cumsum = pca_variance[\"raw\"].cumsum()\n",
    "p50 = np.where(raw_cumsum > 0.50)[0][0]+1\n",
    "p90 = np.where(raw_cumsum > 0.90)[0][0]+1\n",
    "p95 = np.where(raw_cumsum > 0.95)[0][0]+1\n",
    "for size in SIZES:\n",
    "    print(size, end=\"\")\n",
    "    for model_name in [\"AutoEncoder\", \"MultiTask\"]:\n",
    "        model_cumsum = pca_variance[model_name][size].cumsum(axis=1)\n",
    "        for limit in [0.5, 0.9, 0.95]:\n",
    "            idx_lst = np.zeros(10)\n",
    "            for i, row in enumerate(model_cumsum):\n",
    "                idx_lst[i] = np.where(row > limit)[0][0]+1\n",
    "            print(f\" & {idx_lst.mean():.1f} $ \\pm $ {idx_lst.std():.1f}\", end=\"\")\n",
    "    print(r\" \\\\\")\n",
    "print(f\" & {p50} & {p90} & {p95} & {p50} & {p90} & {p95} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ca8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component table\n",
    "for size in SIZES:\n",
    "    print(size, end=\"\")\n",
    "    for model_name in [\"AutoEncoder\", \"MultiTask\"]:\n",
    "        model_variance = pca_variance[model_name][size]\n",
    "        for i in range(2):\n",
    "            print(f\" & {model_variance.mean(axis=0)[i]:.3f} $ \\pm $ {model_variance.std(axis=0)[i]:.3f}\", end=\"\")\n",
    "    print(r\" \\\\\")\n",
    "print(f\"raw & {pca_variance['raw'][0]:.3f} & {pca_variance['raw'][1]:.3f} & {pca_variance['raw'][0]:.3f} & {pca_variance['raw'][1]:.3f} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebaa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variance.mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42465436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance cutoff\n",
    "for model_name in [\"AutoEncoder\", \"MultiTask\"]:\n",
    "    for size in SIZES:\n",
    "        model_variance = pca_variance[model_name][size]\n",
    "        idx_lst = -np.ones((4, 10))\n",
    "        print(model_name, size)\n",
    "        print(model_variance.mean(axis=0))\n",
    "        print(model_variance.std(axis=0))\n",
    "        for j, limit in enumerate([0.01, 0.001, 0.0001, 0.00001]):\n",
    "            for i, row in enumerate(model_variance):\n",
    "                try:\n",
    "                    idx_lst[j, i] = np.where(row >= limit)[0][-1]+1\n",
    "                except:\n",
    "                    break\n",
    "            j_limit = idx_lst[j, :]\n",
    "            j_limit = j_limit[j_limit > -1]\n",
    "            print(f\"{j_limit.mean():.1f} \\pm {j_limit.std():.1f} \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read dataset\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "dataset = Dataset(\n",
    "    info_path=\"../data/GEO_v2/training_data_v3.csv\",\n",
    "    column_path=\"../data/GEO_v2/training_columns.txt\",\n",
    "    path_prefix=\"../\"\n",
    ")\n",
    "\n",
    "X = dataset.test._X\n",
    "colors = dataset.test.dataset_idx\n",
    "\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3156db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot raw pca encodings\n",
    "\n",
    "TAG: NEWFIGS\n",
    "\"\"\"\n",
    "\n",
    "x_pca = pca.fit_transform(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.5, 3.5), dpi=200)\n",
    "ax.scatter(x_pca[:, 0], x_pca[:, 1], s=1, c=colors)\n",
    "\n",
    "ax.set_xlabel(\"Component 1\")\n",
    "ax.set_ylabel(\"Component 2\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "plt.savefig(f\"../figures/results/encodings/dataset_pca_l1000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(9, 7), dpi=200)\n",
    "ax.scatter(x_pca[:, 0], x_pca[:, 1], s=1, c=colors)\n",
    "\n",
    "for ax, architecture, name, size, fold in zip(\n",
    "    [ax1, ax2, ax3, ax4],\n",
    "    [\"AutoEncoder\", \"AutoEncoder\", \"MultiTask\", \"MultiTask\"],\n",
    "    [\"autoencoder\", \"autoencoder\", \"multitask model\", \"multitask model\"],\n",
    "    [7, 64, 10, 32],\n",
    "    [7, 2, 7, 6],\n",
    "):\n",
    "    if architecture == \"AutoEncoder\":\n",
    "        model = AutoEncoder(encoder_layers=[512, 512], latent_dim=size)\n",
    "    elif architecture == \"MultiTask\":\n",
    "        model = MultiTask(encoder_layers=[512, 512], latent_dim=size, num_tasks=dataset.n_tasks)\n",
    "    with open(f\"../models/{architecture}/{size}/{fold}/model.pickle\", \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    encoded = model.encoder(X).detach().numpy()\n",
    "    encoded_pca = pca.fit_transform(encoded)\n",
    "    ax.scatter(encoded_pca[:, 0], encoded_pca[:, 1], s=1, c=colors)\n",
    "\n",
    "    ax.set_xlabel(\"Component 1\")\n",
    "    ax.set_ylabel(\"Component 2\")\n",
    "    ax.set_title(f\"{size}-{name}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "\n",
    "plt.savefig(f\"../figures/results/encodings/dataset_pca_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2415f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
